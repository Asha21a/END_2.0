{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stackoverflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1w4UcOdiSk7",
        "outputId": "f2df9d09-a675-4f38-910f-8956c59dae24"
      },
      "source": [
        "!pip install BeautifulSoup4\n",
        "!pip install XlsxWriter\n",
        "!pip install stackapi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Collecting XlsxWriter\n",
            "  Downloading XlsxWriter-1.4.5-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 14.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-1.4.5\n",
            "Collecting stackapi\n",
            "  Downloading StackAPI-0.2.0.tar.gz (5.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stackapi) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stackapi) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stackapi) (2021.5.30)\n",
            "Building wheels for collected packages: stackapi\n",
            "  Building wheel for stackapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stackapi: filename=StackAPI-0.2.0-py3-none-any.whl size=5857 sha256=6cd8d4ded84ebb26b6aaae02fe965718e33fd1f1512a5e2aa6c6708c7d4b5076\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/db/60/df42a65853e3581c26a2fbb2012a228cb8e267369a3b9ca44d\n",
            "Successfully built stackapi\n",
            "Installing collected packages: stackapi\n",
            "Successfully installed stackapi-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "EJwsw-s5kO6L",
        "outputId": "015346e8-c2ca-44ad-ff69-db26e8d72693"
      },
      "source": [
        "import urllib.request\n",
        "import xlsxwriter\n",
        "from stackapi import StackAPI \n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def get_answer(url):\n",
        "    content = urllib.request.urlopen(url)\n",
        "    soup = BeautifulSoup(content,features='lxml')\n",
        "    try:\n",
        "        answer = soup.find_all('div',attrs={'class':'accepted-answer'})\n",
        "        accepted_content = answer[0].contents[1].find('div',attrs = {'class':'post-text'})\n",
        "        return accepted_content.text\n",
        "    except Exception :\n",
        "        return 'not answered'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tag = 'pytorch'\n",
        "    workbook = xlsxwriter.Workbook(tag+'.xlsx')\n",
        "    worksheet = workbook.add_worksheet()\n",
        "\n",
        "\n",
        "    site = StackAPI('stackoverflow')\n",
        "    questions = site.fetch('questions',tagged = tag)\n",
        "    for i,item in enumerate(questions['items']):\n",
        "        worksheet.write(i,0,item['title'])\n",
        "        worksheet.write(i,1,get_answer(item['link']).strip())\n",
        "\n",
        "    workbook.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c38f4022ff48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mworksheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mworksheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mworkbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-c38f4022ff48>\u001b[0m in \u001b[0;36mget_answer\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'accepted-answer'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m              self.builder.prepare_markup(\n\u001b[0;32m--> 279\u001b[0;31m                  markup, from_encoding, exclude_encodings=exclude_encodings)):\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[0;34m(self, markup, user_specified_encoding, exclude_encodings, document_declared_encoding)\u001b[0m\n\u001b[1;32m    120\u001b[0m         detector = EncodingDetector(\n\u001b[1;32m    121\u001b[0m             markup, try_encodings, is_html, exclude_encodings)\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mencodings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_usable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mchardet_dammit\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m#import chardet.constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#chardet.constants._debug = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/chardet/__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(byte_str)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/chardet/universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLatin1Prober\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m                     self.result = {'encoding': prober.charset_name,\n\u001b[1;32m    213\u001b[0m                                    \u001b[0;34m'confidence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/chardet/charsetgroupprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/chardet/sbcharsetprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m#      _total_char purposes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mCharacterCategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTROL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_char\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAMPLE_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_freq_char\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "btmYF8u0seTH",
        "outputId": "bf873ebd-9ff7-4831-f766-8aa765a775f3"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "res = requests.get(\"https://stackoverflow.com/questions/tagged/pytorch?tab=votes&page={}&pagesize=15\")\n",
        "\n",
        "soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "questions_data = {\n",
        "    \"questions\": []\n",
        "}\n",
        "\n",
        "questions = soup.select(\".question-summary\")\n",
        "\n",
        "for que in questions:\n",
        "    q = que.select_one('.question-hyperlink').getText()\n",
        "    vote_count = que.select_one('.vote-count-post').getText()\n",
        "    views = que.select_one('.views').attrs['title']\n",
        "    answer = que.select_one('.body').attrs['body']\n",
        "    questions_data['questions'].append({\n",
        "        \"question\": q,\n",
        "        \"views\": views,\n",
        "        \"vote_count\": vote_count,\n",
        "        \"answer\": answer\n",
        "    })\n",
        "\n",
        "json_data = json.dumps(questions_data)\n",
        "\n",
        "print(json_data)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4d23c2ce053b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvote_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.vote-count-post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.views'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     questions_data['questions'].append({\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'attrs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb1rOUItwyJM",
        "outputId": "8204c3b8-2ad9-474b-9886-2029e126115d"
      },
      "source": [
        "from stackapi import StackAPI\n",
        "SITE = StackAPI('stackoverflow')\n",
        "SITE.max_pages=1\n",
        "SITE.page_size=10\n",
        "\n",
        "questions = SITE.fetch('questions', min=20, tagged='pytorch', sort='votes')\n",
        "for quest in questions['items']:\n",
        "    if 'title' not in quest or quest['is_answered'] == False:\n",
        "        continue\n",
        "    title = quest['title']\n",
        "    print('Question :- {0}'.format(title))\n",
        "    question_id = quest['question_id']\n",
        "    print('Question ID :- {0}'.format(question_id))\n",
        "    top_answer = SITE.fetch('questions/' + str(question_id) + '/answers', order = 'desc', sort='votes', filter = 'withbody')\n",
        "    print('Most Voted Answer ID :- {0}'.format(top_answer['items'][0]['answer_id']))\n",
        "    print('Answer :- {0}'.format(top_answer['items'][0]['body']))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question :- How to check if pytorch is using the GPU?\n",
            "Question ID :- 48152674\n",
            "Most Voted Answer ID :- 48152675\n",
            "Answer :- <p>This should work:</p>\n",
            "<pre><code>import torch\n",
            "\n",
            "torch.cuda.is_available()\n",
            "&gt;&gt;&gt; True\n",
            "\n",
            "torch.cuda.current_device()\n",
            "&gt;&gt;&gt; 0\n",
            "\n",
            "torch.cuda.device(0)\n",
            "&gt;&gt;&gt; &lt;torch.cuda.device at 0x7efce0b03be0&gt;\n",
            "\n",
            "torch.cuda.device_count()\n",
            "&gt;&gt;&gt; 1\n",
            "\n",
            "torch.cuda.get_device_name(0)\n",
            "&gt;&gt;&gt; 'GeForce GTX 950M'\n",
            "</code></pre>\n",
            "<p>This tells me CUDA is available and can be used in one of your devices (GPUs). And currently, <code>Device 0</code> or the GPU <code>GeForce GTX 950M</code> is being used by <code>PyTorch</code>.</p>\n",
            "\n",
            "Question :- How does the &quot;view&quot; method work in PyTorch?\n",
            "Question ID :- 42479902\n",
            "Most Voted Answer ID :- 42482819\n",
            "Answer :- <p>The view function is meant to reshape the tensor. </p>\n",
            "\n",
            "<p>Say you have a tensor</p>\n",
            "\n",
            "<pre><code>import torch\n",
            "a = torch.range(1, 16)\n",
            "</code></pre>\n",
            "\n",
            "<p><code>a</code> is a tensor that has 16 elements from 1 to 16(included). If you want to reshape this tensor to make it a <code>4 x 4</code> tensor then you can use </p>\n",
            "\n",
            "<pre><code>a = a.view(4, 4)\n",
            "</code></pre>\n",
            "\n",
            "<p>Now <code>a</code> will be a <code>4 x 4</code> tensor. <em>Note that after the reshape the total number of elements need to remain the same. Reshaping the tensor <code>a</code> to a <code>3 x 5</code> tensor would not be appropriate.</em></p>\n",
            "\n",
            "<h3>What is the meaning of parameter -1?</h3>\n",
            "\n",
            "<p>If there is any situation that you don't know how many rows you want but are sure of the number of columns, then you can specify this with a -1. (<em>Note that you can extend this to tensors with more dimensions. Only one of the axis value can be -1</em>). This is a way of telling the library: \"give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen\".</p>\n",
            "\n",
            "<p>This can be seen in the neural network code that you have given above. After the line <code>x = self.pool(F.relu(self.conv2(x)))</code> in the forward function, you will have a 16 depth feature map. You have to flatten this to give it to the fully connected layer. So you tell pytorch to reshape the tensor you obtained to have specific number of columns and tell it to decide the number of rows by itself.</p>\n",
            "\n",
            "<p>Drawing a similarity between numpy and pytorch, <code>view</code> is similar to numpy's <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\" rel=\"noreferrer\">reshape</a> function. </p>\n",
            "\n",
            "Question :- Best way to save a trained model in PyTorch?\n",
            "Question ID :- 42703500\n",
            "Most Voted Answer ID :- 43819235\n",
            "Answer :- <p>I've found <a href=\"https://github.com/pytorch/pytorch/blob/761d6799beb3afa03657a71776412a2171ee7533/docs/source/notes/serialization.rst\" rel=\"noreferrer\">this page</a> on their github repo, I'll just paste the content here.</p>\n",
            "<hr />\n",
            "<h1>Recommended approach for saving a model</h1>\n",
            "<p>There are two main approaches for serializing and restoring a model.</p>\n",
            "<p>The first (recommended) saves and loads only the model parameters:</p>\n",
            "<pre><code>torch.save(the_model.state_dict(), PATH)\n",
            "</code></pre>\n",
            "<p>Then later:</p>\n",
            "<pre><code>the_model = TheModelClass(*args, **kwargs)\n",
            "the_model.load_state_dict(torch.load(PATH))\n",
            "</code></pre>\n",
            "<p>The second saves and loads the entire model:</p>\n",
            "<pre><code>torch.save(the_model, PATH)\n",
            "</code></pre>\n",
            "<p>Then later:</p>\n",
            "<pre><code>the_model = torch.load(PATH)\n",
            "</code></pre>\n",
            "<p>However in this case, the serialized data is bound to the specific classes\n",
            "and the exact directory structure used, so it can break in various ways when\n",
            "used in other projects, or after some serious refactors.</p>\n",
            "\n",
            "Question :- Model summary in pytorch\n",
            "Question ID :- 42480111\n",
            "Most Voted Answer ID :- 49989438\n",
            "Answer :- <p>Yes, you can get exact Keras representation, using the <a href=\"https://github.com/sksq96/pytorch-summary\" rel=\"noreferrer\">pytorch-summary</a> package.</p>\n",
            "<p>Example for VGG16:</p>\n",
            "<pre><code>from torchvision import models\n",
            "from torchsummary import summary\n",
            "\n",
            "vgg = models.vgg16()\n",
            "summary(vgg, (3, 224, 224))\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "           Linear-32                 [-1, 4096]     102,764,544\n",
            "             ReLU-33                 [-1, 4096]               0\n",
            "          Dropout-34                 [-1, 4096]               0\n",
            "           Linear-35                 [-1, 4096]      16,781,312\n",
            "             ReLU-36                 [-1, 4096]               0\n",
            "          Dropout-37                 [-1, 4096]               0\n",
            "           Linear-38                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.59\n",
            "Params size (MB): 527.79\n",
            "Estimated Total Size (MB): 746.96\n",
            "----------------------------------------------------------------\n",
            "</code></pre>\n",
            "\n",
            "Question :- Why do we need to call zero_grad() in PyTorch?\n",
            "Question ID :- 48001598\n",
            "Most Voted Answer ID :- 48009142\n",
            "Answer :- <p>In <a href=\"https://github.com/pytorch/pytorch\" rel=\"noreferrer\"><code>PyTorch</code></a>, we need to set the gradients to zero before starting to do backpropragation because PyTorch <em>accumulates the gradients</em> on subsequent backward passes. This is convenient while training RNNs. So, the default action is to <a href=\"https://pytorch.org/docs/stable/_modules/torch/autograd.html\" rel=\"noreferrer\">accumulate (i.e. sum) the gradients</a> on every <code>loss.backward()</code> call.</p>\n",
            "<p>Because of this, when you start your training loop, ideally you should <a href=\"https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer.zero_grad\" rel=\"noreferrer\"><code>zero out the gradients</code></a> so that you do the parameter update correctly. Else the gradient would point in some other direction than the intended direction towards the <em>minimum</em> (or <em>maximum</em>, in case of maximization objectives).</p>\n",
            "<p>Here is a simple example:</p>\n",
            "<pre><code>import torch\n",
            "from torch.autograd import Variable\n",
            "import torch.optim as optim\n",
            "\n",
            "def linear_model(x, W, b):\n",
            "    return torch.matmul(x, W) + b\n",
            "\n",
            "data, targets = ...\n",
            "\n",
            "W = Variable(torch.randn(4, 3), requires_grad=True)\n",
            "b = Variable(torch.randn(3), requires_grad=True)\n",
            "\n",
            "optimizer = optim.Adam([W, b])\n",
            "\n",
            "for sample, target in zip(data, targets):\n",
            "    # clear out the gradients of all Variables \n",
            "    # in this optimizer (i.e. W, b)\n",
            "    optimizer.zero_grad()\n",
            "    output = linear_model(sample, W, b)\n",
            "    loss = (output - target) ** 2\n",
            "    loss.backward()\n",
            "    optimizer.step()\n",
            "</code></pre>\n",
            "<hr />\n",
            "<p>Alternatively, if you're doing a <em>vanilla gradient descent</em>, then:</p>\n",
            "<pre><code>W = Variable(torch.randn(4, 3), requires_grad=True)\n",
            "b = Variable(torch.randn(3), requires_grad=True)\n",
            "\n",
            "for sample, target in zip(data, targets):\n",
            "    # clear out the gradients of Variables \n",
            "    # (i.e. W, b)\n",
            "    W.grad.data.zero_()\n",
            "    b.grad.data.zero_()\n",
            "\n",
            "    output = linear_model(sample, W, b)\n",
            "    loss = (output - target) ** 2\n",
            "    loss.backward()\n",
            "\n",
            "    W -= learning_rate * W.grad.data\n",
            "    b -= learning_rate * b.grad.data\n",
            "</code></pre>\n",
            "<hr />\n",
            "<p><strong>Note</strong>:</p>\n",
            "<ul>\n",
            "<li>The <em>accumulation</em> (i.e. <em>sum</em>) of gradients happen when <a href=\"https://pytorch.org/docs/stable/_modules/torch/autograd.html\" rel=\"noreferrer\"><code>.backward()</code> is called on the <code>loss</code> tensor</a>.</li>\n",
            "<li>As of v1.7.0, there's an option of resetting the gradients with <code>None</code> <a href=\"https://pytorch.org/docs/stable/_modules/torch/optim/optimizer.html#Optimizer.zero_grad\" rel=\"noreferrer\"><code>optimizer.zero_grad(set_to_none=True)</code></a> instead of filling it with a tensor of zeroes. The docs claim that this setting will result in lower memory requirements and a slight improvement in performance but it might be error-prone, if not handled carefully.</li>\n",
            "</ul>\n",
            "\n",
            "Question :- How to initialize weights in PyTorch?\n",
            "Question ID :- 49433936\n",
            "Most Voted Answer ID :- 49433937\n",
            "Answer :- <h1>Single layer</h1>\n",
            "<p>To initialize the weights of a single layer, use a function from <a href=\"https://pytorch.org/docs/master/nn.init.html\" rel=\"nofollow noreferrer\"><code>torch.nn.init</code></a>. For instance:</p>\n",
            "<pre><code>conv1 = torch.nn.Conv2d(...)\n",
            "torch.nn.init.xavier_uniform(conv1.weight)\n",
            "</code></pre>\n",
            "<p>Alternatively, you can modify the parameters by writing to <code>conv1.weight.data</code> (which is a <a href=\"http://pytorch.org/docs/master/tensors.html#torch.Tensor\" rel=\"nofollow noreferrer\"><code>torch.Tensor</code></a>). Example:</p>\n",
            "<pre><code>conv1.weight.data.fill_(0.01)\n",
            "</code></pre>\n",
            "<p>The same applies for biases:</p>\n",
            "<pre><code>conv1.bias.data.fill_(0.01)\n",
            "</code></pre>\n",
            "<h2><code>nn.Sequential</code> or custom <code>nn.Module</code></h2>\n",
            "<p>Pass an initialization function to <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Module.apply\" rel=\"nofollow noreferrer\"><code>torch.nn.Module.apply</code></a>. It will initialize the weights in the entire <code>nn.Module</code> recursively.</p>\n",
            "<blockquote>\n",
            "<p><strong>apply(<em>fn</em>):</strong> Applies <code>fn</code> recursively to every submodule (as returned by <code>.children()</code>) as well as self. Typical use includes initializing the parameters of a model (see also torch-nn-init).</p>\n",
            "</blockquote>\n",
            "<p>Example:</p>\n",
            "<pre><code>def init_weights(m):\n",
            "    if isinstance(m, nn.Linear):\n",
            "        torch.nn.init.xavier_uniform(m.weight)\n",
            "        m.bias.data.fill_(0.01)\n",
            "\n",
            "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
            "net.apply(init_weights)\n",
            "</code></pre>\n",
            "\n",
            "Question :- What&amp;#39;s the difference between reshape and view in pytorch?\n",
            "Question ID :- 49643225\n",
            "Most Voted Answer ID :- 49644300\n",
            "Answer :- <p><code>torch.view</code> has existed for a long time. It will return a tensor with the new shape. The returned tensor will share the underling data with the original tensor. \n",
            "See the <a href=\"http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\" rel=\"noreferrer\">documentation here</a>.</p>\n",
            "\n",
            "<p>On the other hand, it seems that <code>torch.reshape</code> <a href=\"https://github.com/pytorch/pytorch/pull/5575\" rel=\"noreferrer\">has been introduced recently in version 0.4</a>. According to the <a href=\"http://pytorch.org/docs/master/torch.html#torch.reshape\" rel=\"noreferrer\">document</a>, this method will</p>\n",
            "\n",
            "<blockquote>\n",
            "  <p>Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior.</p>\n",
            "</blockquote>\n",
            "\n",
            "<p>It means that <code>torch.reshape</code> may return a copy or a view of the original tensor. You can not count on that to return a view or a copy. According to the developer:</p>\n",
            "\n",
            "<blockquote>\n",
            "  <p>if you need a copy use clone() if you need the same storage use view(). The semantics of reshape() are that it may or may not share the storage and you don't know beforehand.</p>\n",
            "</blockquote>\n",
            "\n",
            "<p>Another difference is that <code>reshape()</code> can operate on both contiguous and non-contiguous tensor while <code>view()</code> can only operate on contiguous tensor. Also see <a href=\"https://stackoverflow.com/a/26999092/6064933\">here</a> about the meaning of <code>contiguous</code>.</p>\n",
            "\n",
            "Question :- PyTorch - What does contiguous() do?\n",
            "Question ID :- 48915810\n",
            "Most Voted Answer ID :- 52229694\n",
            "Answer :- <p>There are a few operations on Tensors in PyTorch that do not change the contents of a tensor, but change the way the data is organized. These operations include:</p>\n",
            "<blockquote>\n",
            "<p><code>narrow()</code>, <code>view()</code>, <code>expand()</code> and <code>transpose()</code></p>\n",
            "</blockquote>\n",
            "<p><em>For example:</em> when you call <code>transpose()</code>, PyTorch doesn't generate a new tensor with a new layout, it just modifies meta information in the Tensor object so that the offset and stride describe the desired new shape. In this example, the transposed tensor and original tensor share the same memory:</p>\n",
            "<pre class=\"lang-py prettyprint-override\"><code>x = torch.randn(3,2)\n",
            "y = torch.transpose(x, 0, 1)\n",
            "x[0, 0] = 42\n",
            "print(y[0,0])\n",
            "# prints 42\n",
            "</code></pre>\n",
            "<p>This is where the concept of <em>contiguous</em> comes in. In the example above, <code>x</code> is contiguous but <code>y</code> is not because its memory layout is different to that of a tensor of same shape made from scratch. Note that the word <em>&quot;contiguous&quot;</em> is a bit misleading because it's not that the content of the tensor is spread out around disconnected blocks of memory. Here bytes are still allocated in one block of memory but the order of the elements is different!</p>\n",
            "<p>When you call <code>contiguous()</code>, it actually makes a copy of the tensor such that the order of its elements in memory is the same as if it had been created from scratch with the same data.</p>\n",
            "<p>Normally you don't need to worry about this. You're generally safe to assume everything will work, and wait until you get a <code>RuntimeError: input is not contiguous</code> where PyTorch expects a contiguous tensor to add a call to <code>contiguous()</code>.</p>\n",
            "\n",
            "Question :- Why do we &amp;quot;pack&amp;quot; the sequences in PyTorch?\n",
            "Question ID :- 51030782\n",
            "Most Voted Answer ID :- 51030945\n",
            "Answer :- <p>I have stumbled upon this problem too and below is what I figured out.</p>\n",
            "<p>When training RNN (LSTM or GRU or vanilla-RNN), it is difficult to batch the variable length sequences. For example: if the length of sequences in a size 8 batch is [4,6,8,5,4,3,7,8], you will pad all the sequences and that will result in 8 sequences of length 8. You would end up doing 64 computations (8x8), but you needed to do only 45 computations. Moreover, if you wanted to do something fancy like using a bidirectional-RNN, it would be harder to do batch computations just by padding and you might end up doing more computations than required.</p>\n",
            "<p>Instead, PyTorch allows us to pack the sequence, internally packed sequence is a tuple of two lists. One contains the elements of sequences. Elements are interleaved by time steps (see example below) and other contains the <s>size of each sequence</s> the batch size at each step. This is helpful in recovering the actual sequences as well as telling RNN what is the batch size at each time step. This has been pointed by @Aerin.  This can be passed to RNN and it will internally optimize the computations.</p>\n",
            "<p>I might have been unclear at some points, so let me know and I can add more explanations.</p>\n",
            "<p>Here's a code example:</p>\n",
            "<pre><code> a = [torch.tensor([1,2,3]), torch.tensor([3,4])]\n",
            " b = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)\n",
            " &gt;&gt;&gt;&gt;\n",
            " tensor([[ 1,  2,  3],\n",
            "    [ 3,  4,  0]])\n",
            " torch.nn.utils.rnn.pack_padded_sequence(b, batch_first=True, lengths=[3,2])\n",
            " &gt;&gt;&gt;&gt;PackedSequence(data=tensor([ 1,  3,  2,  4,  3]), batch_sizes=tensor([ 2,  2,  1]))\n",
            "</code></pre>\n",
            "\n",
            "Question :- Pytorch, what are the gradient arguments\n",
            "Question ID :- 43451125\n",
            "Most Voted Answer ID :- 47026836\n",
            "Answer :- <h1>Explanation</h1>\n",
            "\n",
            "<p>For neural networks, we usually use <code>loss</code> to assess how well the network has learned to classify the input image (or other tasks). The <code>loss</code> term is usually a scalar value. In order to update the parameters of the network, we need to calculate the gradient of <code>loss</code> w.r.t to the parameters, which is actually <code>leaf node</code> in the computation graph (by the way, these parameters are mostly the weight and bias of various layers such Convolution, Linear and so on).</p>\n",
            "\n",
            "<p>According to chain rule, in order to calculate gradient of <code>loss</code> w.r.t to a leaf node, we can compute derivative of <code>loss</code> w.r.t some intermediate variable, and gradient of intermediate variable w.r.t to the leaf variable, do a dot product and sum all these up.</p>\n",
            "\n",
            "<p>The <code>gradient</code> arguments of a <code>Variable</code>'s <a href=\"http://pytorch.org/docs/master/autograd.html#torch.autograd.Variable.backward\" rel=\"noreferrer\"><code>backward()</code></a> method is used to <strong>calculate a weighted sum of each element of a Variable w.r.t the <a href=\"https://discuss.pytorch.org/t/leaf-variable-was-used-in-an-inplace-operation/308/2?u=jdhao\" rel=\"noreferrer\">leaf Variable</a>.</strong> These weight is just the derivate of final <code>loss</code> w.r.t each element of the intermediate variable.</p>\n",
            "\n",
            "<h1>A concrete example</h1>\n",
            "\n",
            "<p>Let's take a concrete and simple example to understand this.</p>\n",
            "\n",
            "<pre class=\"lang-py prettyprint-override\"><code>from torch.autograd import Variable\n",
            "import torch\n",
            "x = Variable(torch.FloatTensor([[1, 2, 3, 4]]), requires_grad=True)\n",
            "z = 2*x\n",
            "loss = z.sum(dim=1)\n",
            "\n",
            "# do backward for first element of z\n",
            "z.backward(torch.FloatTensor([[1, 0, 0, 0]]), retain_graph=True)\n",
            "print(x.grad.data)\n",
            "x.grad.data.zero_() #remove gradient in x.grad, or it will be accumulated\n",
            "\n",
            "# do backward for second element of z\n",
            "z.backward(torch.FloatTensor([[0, 1, 0, 0]]), retain_graph=True)\n",
            "print(x.grad.data)\n",
            "x.grad.data.zero_()\n",
            "\n",
            "# do backward for all elements of z, with weight equal to the derivative of\n",
            "# loss w.r.t z_1, z_2, z_3 and z_4\n",
            "z.backward(torch.FloatTensor([[1, 1, 1, 1]]), retain_graph=True)\n",
            "print(x.grad.data)\n",
            "x.grad.data.zero_()\n",
            "\n",
            "# or we can directly backprop using loss\n",
            "loss.backward() # equivalent to loss.backward(torch.FloatTensor([1.0]))\n",
            "print(x.grad.data)    \n",
            "</code></pre>\n",
            "\n",
            "<p>In the above example, the outcome of first <code>print</code> is</p>\n",
            "\n",
            "<blockquote>\n",
            "  <p>2  0  0  0<br>\n",
            "  [torch.FloatTensor of size 1x4]</p>\n",
            "</blockquote>\n",
            "\n",
            "<p>which is exactly the derivative of z_1 w.r.t to x.</p>\n",
            "\n",
            "<p>The outcome of second <code>print</code> is :</p>\n",
            "\n",
            "<blockquote>\n",
            "  <p>0  2  0  0<br>\n",
            "  [torch.FloatTensor of size 1x4]</p>\n",
            "</blockquote>\n",
            "\n",
            "<p>which is the derivative of z_2 w.r.t to x.</p>\n",
            "\n",
            "<p>Now if use a weight of [1, 1, 1, 1] to calculate the derivative of z w.r.t to x, the outcome is <code>1*dz_1/dx + 1*dz_2/dx + 1*dz_3/dx + 1*dz_4/dx</code>. So no surprisingly, the output of 3rd <code>print</code> is:</p>\n",
            "\n",
            "<blockquote>\n",
            "  <p>2  2  2  2<br>\n",
            "  [torch.FloatTensor of size 1x4]</p>\n",
            "</blockquote>\n",
            "\n",
            "<p>It should be noted that weight vector [1, 1, 1, 1] is exactly derivative of <code>loss</code> w.r.t to z_1, z_2, z_3 and z_4. The derivative of <code>loss</code> w.r.t to <code>x</code> is calculated as:</p>\n",
            "\n",
            "<pre><code>d(loss)/dx = d(loss)/dz_1 * dz_1/dx + d(loss)/dz_2 * dz_2/dx + d(loss)/dz_3 * dz_3/dx + d(loss)/dz_4 * dz_4/dx\n",
            "</code></pre>\n",
            "\n",
            "<p>So the output of 4th <code>print</code> is the same as the 3rd <code>print</code>:</p>\n",
            "\n",
            "<blockquote>\n",
            "  <p>2  2  2  2<br>\n",
            "  [torch.FloatTensor of size 1x4]</p>\n",
            "</blockquote>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "ZpbT1VhbuQjT",
        "outputId": "9e61e71d-abb4-4dfb-8e17-a47666445e6b"
      },
      "source": [
        "from stackapi import StackAPI, StackAPIError\n",
        "try:\n",
        "    SITE = StackAPI('stackoverflow', key=SETTINGS['xxxxxxx'])\n",
        "    SITE.max_pages=100\n",
        "    SITE.page_size=1000000000\n",
        "    post = SITE.fetch('posts', ids=[59115355, 2901002], sort='activity', order='desc')\n",
        "except StackAPIError as e:\n",
        "    print(e.message)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2d62991a5107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstackapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackAPIError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mSITE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stackoverflow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSETTINGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xxxxxxx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mSITE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mSITE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SETTINGS' is not defined"
          ]
        }
      ]
    }
  ]
}