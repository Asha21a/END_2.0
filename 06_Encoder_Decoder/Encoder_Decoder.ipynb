{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder_Decoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "4ypX-MICj4EY",
        "outputId": "30a56d80-fb8d-4ab6-a094-e5e5fee1a64c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/tweets.csv\")\n",
        "df.head()"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0oF55QYnBj1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7olNR_ziq1NZ",
        "outputId": "ed1f95ec-499c-45b0-d4bd-4b0e0f3c7b9c"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgSVs5_4rNCc"
      },
      "source": [
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5zLagqfscIu",
        "outputId": "007e1a30-f069-4060-94ba-177f1fe06bf3"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0a0f93dd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPaSMqMzsgpI"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvaYhCJ3tJog"
      },
      "source": [
        "fields = [('tweet', Tweet), ('label', Label)]"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqDDF2BytNgo"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])]"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgszLGcmtQxM"
      },
      "source": [
        "twitterDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw3X_z9itTXU"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[85, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfGs4NC2tWTg",
        "outputId": "0cea3c58-475a-4ed0-b37f-a2e121e64a4f"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXXKfkCEtFza",
        "outputId": "2914e11a-61d5-4cca-bb04-e48449ddb359"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'tweet': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arXdVcJUtCgP"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BanIb74ls_xr",
        "outputId": "ea415dba-989c-4d68-a5de-395fdef0d416"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl3-k0PDs7-W",
        "outputId": "c65fba6c-d0af-49d1-c5b5-23abc20ea7ea"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9p2wevs3id"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaS6L5M6szzZ",
        "outputId": "ef39cfac-6a7b-45a3-8dc2-52929a60e4da"
      },
      "source": [
        "next(iter(train_iterator))\n",
        "#len(train.examples[10].tweet)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 32]\n",
              "\t[.tweet]:('[torch.LongTensor of size 32x8]', '[torch.LongTensor of size 32]')\n",
              "\t[.label]:[torch.LongTensor of size 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MRyhnnNsyou"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXA78ORVrlLb"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Encoder(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers):\n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           #dropout=dropout,\n",
        "                           batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        # pass to encoder\n",
        "        packed_output, (hidden_encoder, cell_encoder) = self.encoder(packed_embedded)\n",
        "\n",
        "        # unpack sequence\n",
        "        encoder_output, encoder_output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "    \n",
        "        # encoder o/p for decoder ; embedded for visualization purpose\n",
        "        return encoder_output, embedded"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwgjQV5wsAMI"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300 \n",
        "num_hidden_nodes = 100\n",
        "num_layers = 1\n",
        "\n",
        "# Instantiate the Encoder\n",
        "encoder = Encoder(size_of_vocab, embedding_dim, num_hidden_nodes, num_layers)"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgfcDGbmuP_K",
        "outputId": "be4ab72c-48f6-4cfe-fdb8-b88cf5f6ae22"
      },
      "source": [
        "print(encoder)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(encoder):\n",
        "    return sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The encoder has {count_parameters(encoder):,} trainable parameters')"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): LSTM(300, 100, batch_first=True)\n",
            ")\n",
            "The encoder has 1,556,100 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znm8n5xjsKwX"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, encoder_output_dim, hidden_dim, output_dim, n_layers):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # LSTM layer\n",
        "        self.decoder = nn.LSTM(encoder_output_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           batch_first=True)\n",
        "\n",
        "        self.fc= nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, encoder_output):\n",
        "        \n",
        "        # pass to decoder\n",
        "        output, (hidden_decoder, cell_decoder) = self.decoder(encoder_output)\n",
        "\n",
        "        # Linear\n",
        "        dense_outputs = self.fc(hidden_decoder)   \n",
        "\n",
        "        final_output = F.softmax(dense_outputs[0], dim=1)\n",
        "\n",
        "        # final_output is prediction & output is decoder output for visualization purpose\n",
        "        return final_output, output"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kIhYSSJsQ_e"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "encoder_output_dim = 100\n",
        "n_hidden_nodes = 70\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "\n",
        "# Instantiate the Decoder\n",
        "decoder = Decoder(size_of_vocab, encoder_output_dim, n_hidden_nodes, num_output_nodes, num_layers)"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzqQYg_BudgW",
        "outputId": "58a46e82-a903-46d7-b5bf-024b73ddc0c2"
      },
      "source": [
        "print(decoder)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(decoder):\n",
        "    return sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The decoder has {count_parameters(decoder):,} trainable parameters')"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder(\n",
            "  (decoder): LSTM(100, 70, batch_first=True)\n",
            "  (fc): Linear(in_features=70, out_features=3, bias=True)\n",
            ")\n",
            "The decoder has 48,373 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ODnX5GB5Up"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=2e-4)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXdf5Cc4sVt_"
      },
      "source": [
        "def train(encoder, decoder, iterator, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    encoder.train()  \n",
        "    decoder.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        encoder_optimizer.zero_grad()   \n",
        "        decoder_optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweet  \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        encoder_out, embedding = encoder(tweet, tweet_lengths)\n",
        "        \n",
        "        predictions, decoder_out = decoder(encoder_out)\n",
        "        predictions = predictions.squeeze() \n",
        "\n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT53r4WZshOo"
      },
      "source": [
        "def evaluate(encoder, decoder, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweet\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            encoder_out, embedding = encoder(tweet, tweet_lengths)\n",
        "        \n",
        "            predictions , decoder_out = decoder(encoder_out)\n",
        "            predictions = predictions.squeeze() \n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdLLDOYfs2Rl",
        "outputId": "90ac78ac-9766-43eb-e40e-937e888c22a4"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(encoder, decoder, train_iterator, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(encoder, decoder, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(encoder.state_dict(), 'encoder_saved_weights.pt')\n",
        "        torch.save(decoder.state_dict(), 'decoder_saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')\n",
        "    \n",
        "    trainLoss.append(train_loss)\n",
        "    validLoss.append(valid_loss)\n",
        "\n",
        "    trainAcc.append(train_acc)\n",
        "    validAcc.append(valid_acc)"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.071 | Train Acc: 64.73%\n",
            "\t Val. Loss: 1.045 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.975 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.900 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.874 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.873 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.864 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.866 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.855 | Train Acc: 69.72%\n",
            "\t Val. Loss: 0.854 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.828 | Train Acc: 72.08%\n",
            "\t Val. Loss: 0.844 |  Val. Acc: 71.43% \n",
            "\n",
            "\tTrain Loss: 0.799 | Train Acc: 77.96%\n",
            "\t Val. Loss: 0.835 |  Val. Acc: 72.77% \n",
            "\n",
            "\tTrain Loss: 0.769 | Train Acc: 80.66%\n",
            "\t Val. Loss: 0.828 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 0.729 | Train Acc: 85.56%\n",
            "\t Val. Loss: 0.824 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 0.701 | Train Acc: 87.42%\n",
            "\t Val. Loss: 0.810 |  Val. Acc: 76.34% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-bLZQ2bs6LR"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "en_path='./encoder_saved_weights.pt'\n",
        "encoder.load_state_dict(torch.load(en_path));\n",
        "encoder.eval();\n",
        "\n",
        "de_path='./decoder_saved_weights.pt'\n",
        "decoder.load_state_dict(torch.load(de_path));\n",
        "decoder.eval();\n",
        "\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    encoder_out, embedding = encoder(tensor, length_tensor)\n",
        "    prediction, decoder_out = decoder(encoder_out)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DRj_0mnCDh-k",
        "outputId": "2fbb5e39-dd34-423e-8ac2-8c31e153eb76"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    }
  ]
}